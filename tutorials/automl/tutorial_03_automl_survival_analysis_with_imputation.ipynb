{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "032d8ad4",
   "metadata": {},
   "source": [
    "# Tutorial: Survival Analysis AutoML with imputation\n",
    "\n",
    "Welcome to the Survival analysis AutoML tutorial!\n",
    "\n",
    "This tutorial will show how to use AutoPrognosis to learn a model for datasets with missing data. We show how to use a predefined imputer or how to use AutoPrognosis to select the optimal imputer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3dc094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stdlib\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "# third party\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# autoprognosis absolute\n",
    "import autoprognosis.logger as log\n",
    "from autoprognosis.studies.risk_estimation import RiskEstimationStudy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ec7b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "log.add(sink=sys.stderr, level=\"INFO\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0827f5",
   "metadata": {},
   "source": [
    "## Load dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45ad99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycox import datasets\n",
    "\n",
    "df = datasets.gbsg.read_df()\n",
    "df = df[df[\"duration\"] > 0]\n",
    "\n",
    "X = df.drop(columns = [\"duration\", \"event\"])\n",
    "T = df[\"duration\"]\n",
    "Y = df[\"event\"]\n",
    "\n",
    "eval_time_horizons = [\n",
    "    int(T[Y.iloc[:] == 1].quantile(0.50)),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff99eed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "total_len = len(X)\n",
    "\n",
    "for col in [\"x3\", \"x4\"]:\n",
    "    indices = random.sample(range(0, total_len), 10)\n",
    "    X.loc[indices, col] = np.nan\n",
    "\n",
    "X.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8bcb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = X.copy()\n",
    "dataset[\"target\"] = Y\n",
    "dataset[\"time_to_event\"] = T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343a2ff6",
   "metadata": {},
   "source": [
    "## Option 1: Predefined imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b0146a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stdlib\n",
    "from pathlib import Path\n",
    "\n",
    "workspace = Path(\"workspace\")\n",
    "study_name = \"test_risk_estimation_studies\"\n",
    "\n",
    "study = RiskEstimationStudy(\n",
    "    study_name=study_name,\n",
    "    dataset=dataset,\n",
    "    target=\"target\",\n",
    "    time_to_event=\"time_to_event\",\n",
    "    time_horizons=eval_time_horizons,\n",
    "    num_iter=2, # DELETE THIS LINE FOR BETTER RESULTS. \n",
    "    num_study_iter=1, # DELETE THIS LINE FOR BETTER RESULTS. \n",
    "    risk_estimators=[\"cox_ph\", \"lognormal_aft\", \"survival_xgboost\"], # DELETE THIS LINE FOR BETTER RESULTS. \n",
    "    imputers=[\"mean\"],\n",
    "    feature_scaling=[\"minmax_scaler\", \"nop\"], # DELETE THIS LINE FOR BETTER RESULTS. \n",
    "    score_threshold=0.4,\n",
    "    workspace=workspace,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d2219c",
   "metadata": {},
   "outputs": [],
   "source": [
    "study.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2903d9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# autoprognosis absolute\n",
    "from autoprognosis.plugins.imputers import Imputers\n",
    "from autoprognosis.utils.serialization import load_model_from_file\n",
    "from autoprognosis.utils.tester import evaluate_survival_estimator\n",
    "\n",
    "model_path = workspace / study_name / \"model.p\"\n",
    "\n",
    "model = load_model_from_file(model_path)\n",
    "\n",
    "X_imp = Imputers().get(\"mean\").fit_transform(X)\n",
    "\n",
    "evaluate_survival_estimator(model, X_imp, T, Y, eval_time_horizons)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2680f42",
   "metadata": {},
   "source": [
    "##  Option 2: Let the optimizer find the best imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072f65a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stdlib\n",
    "from pathlib import Path\n",
    "\n",
    "workspace = Path(\"workspace\")\n",
    "workspace.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "study_name = \"test_risk_estimation_studies_v2\"\n",
    "\n",
    "study = RiskEstimationStudy(\n",
    "    study_name=study_name,\n",
    "    dataset=dataset,\n",
    "    target=\"target\",\n",
    "    time_to_event=\"time_to_event\",\n",
    "    time_horizons=eval_time_horizons,\n",
    "    num_iter=2, # DELETE THIS LINE FOR BETTER RESULTS. \n",
    "    num_study_iter=1, # DELETE THIS LINE FOR BETTER RESULTS. \n",
    "    risk_estimators=[\"cox_ph\", \"lognormal_aft\", \"survival_xgboost\"], # DELETE THIS LINE FOR BETTER RESULTS. \n",
    "    imputers=[\"mean\", \"ice\", \"median\"], # DELETE THIS LINE FOR BETTER RESULTS. \n",
    "    feature_scaling=[\"minmax_scaler\", \"nop\"], # DELETE THIS LINE FOR BETTER RESULTS. \n",
    "    score_threshold=0.4,\n",
    "    workspace=workspace,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6ebb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "study.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a637d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# autoprognosis absolute\n",
    "from autoprognosis.utils.serialization import load_model_from_file\n",
    "from autoprognosis.utils.tester import evaluate_survival_estimator\n",
    "\n",
    "model_path = workspace / study_name / \"model.p\"\n",
    "\n",
    "model = load_model_from_file(model_path)\n",
    "\n",
    "evaluate_survival_estimator(model, X, T, Y, eval_time_horizons)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62943458",
   "metadata": {},
   "source": [
    "## Congratulations!\n",
    "\n",
    "Congratulations on completing this notebook tutorial! If you enjoyed this and would like to join the movement towards Machine learning and AI for medicine, you can do so in the following ways!\n",
    "\n",
    "### Star AutoPrognosis on GitHub\n",
    "\n",
    "The easiest way to help our community is just by starring the Repos! This helps raise awareness of the tools we're building.\n",
    "\n",
    "- [Star AutoPrognosis](https://github.com/vanderschaarlab/autoprognosis)\n",
    "- [Star HyperImpute](https://github.com/vanderschaarlab/hyperimpute)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
